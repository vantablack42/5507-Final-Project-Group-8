{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "import json\n",
    "payload = {}\n",
    "headers = {\n",
    "  'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "  'accept-language': 'zh-CN,zh;q=0.9',\n",
    "  'cache-control': 'max-age=0',\n",
    "  'cookie': 'bid=Gf8N7P12IX4; _pk_id.100001.8cb4=21d1d1676cf974fb.1730562677.; push_noty_num=0; push_doumail_num=0; __utmv=30149280.28449; __yadk_uid=bfc7tcSoGAJaCTBf6xXlS1wh1vmjTXkB; douban-fav-remind=1; ll=\"108090\"; _pk_ref.100001.8cb4=%5B%22%22%2C%22%22%2C1733833751%2C%22https%3A%2F%2Fsec.douban.com%2F%22%5D; _pk_ses.100001.8cb4=1; __utma=30149280.765760.1730562679.1732791937.1733833752.30; __utmc=30149280; __utmz=30149280.1733833752.30.3.utmcsr=sec.douban.com|utmccn=(referral)|utmcmd=referral|utmcct=/; dbcl2=\"284492976:qnvQffiWDMY\"; ck=_q0I; frodotk_db=\"69e131bac12d80803da3953043888180\"; __utmt=1; __utmb=30149280.92.6.1733834358581',\n",
    "  'priority': 'u=0, i',\n",
    "  'referer': 'https://www.douban.com/group/649970/',\n",
    "  'sec-ch-ua': '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "  'sec-ch-ua-mobile': '?0',\n",
    "  'sec-ch-ua-platform': '\"Windows\"',\n",
    "  'sec-fetch-dest': 'document',\n",
    "  'sec-fetch-mode': 'navigate',\n",
    "  'sec-fetch-site': 'same-origin',\n",
    "  'sec-fetch-user': '?1',\n",
    "  'upgrade-insecure-requests': '1',\n",
    "  'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>username</th>\n",
       "      <th>post_time</th>\n",
       "      <th>post_content</th>\n",
       "      <th>replies</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>闲鱼买哔站大会员被诈骗</td>\n",
       "      <td>十七岁的某某</td>\n",
       "      <td>2024-12-10 00:23:31</td>\n",
       "      <td>在闲鱼买哔站大会员，找了个尤其便宜的（比其他价格便宜一半），赌了一把，然后被骗了两个298！...</td>\n",
       "      <td>小红书上很多相同受骗的，也有追款成功得，例如：60 ustinian发布了一篇小红书笔记，快...</td>\n",
       "      <td>https://www.douban.com/group/topic/314970304/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title username            post_time  \\\n",
       "0  闲鱼买哔站大会员被诈骗   十七岁的某某  2024-12-10 00:23:31   \n",
       "\n",
       "                                        post_content  \\\n",
       "0  在闲鱼买哔站大会员，找了个尤其便宜的（比其他价格便宜一半），赌了一把，然后被骗了两个298！...   \n",
       "\n",
       "                                             replies  \\\n",
       "0  小红书上很多相同受骗的，也有追款成功得，例如：60 ustinian发布了一篇小红书笔记，快...   \n",
       "\n",
       "                                             url  \n",
       "0  https://www.douban.com/group/topic/314970304/  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 豆瓣小组ID\n",
    "group_ids = ['305169', '460410', '729922', '6922146', '245004', '294553', '163511', '676966', '538991', '608017', '305169', '693032', '584640', '584640', '723775', '690137', '460410', '387701', '649970']\n",
    "start = 1  # 从第几页开始爬取\n",
    "end = 1    # 在第几页结束爬取\n",
    "\n",
    "# 初始化数据存储\n",
    "headlines = []\n",
    "web_urls = []\n",
    "dates = []\n",
    "authors = []\n",
    "post_content = []\n",
    "comments_list = []\n",
    "\n",
    "requested_urls = set()  # 存储已请求过的链接，避免重复爬取\n",
    "\n",
    "# 获取当前时间\n",
    "now = datetime.now()\n",
    "\n",
    "# 逐组爬取\n",
    "for group in group_ids:\n",
    "    for page in range(start, end + 1):\n",
    "        url = f'https://www.douban.com/group/{group}/discussion?start={(page - 1) * 25}&type=new'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        rows = soup.select('tr')  # 查找所有行\n",
    "        for row in rows:\n",
    "            title_element = row.select_one('td.title > a')   \n",
    "            author_element = row.select_one('td:nth-child(2) > a')\n",
    "\n",
    "            # 检查帖子是否有标题和作者\n",
    "            if title_element and author_element:\n",
    "                link = title_element['href']\n",
    "\n",
    "                # 请求帖子内容\n",
    "                post_response = requests.get(link, headers=headers)\n",
    "                post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "\n",
    "                # 提取发布时间并检查是否在过去24小时内\n",
    "                time_element = post_soup.select_one('.create-time')\n",
    "                if time_element:\n",
    "                    time_value = time_element.text.strip()\n",
    "                    try:\n",
    "                        post_time = datetime.strptime(time_value, '%Y-%m-%d %H:%M:%S')  # 包含秒\n",
    "                    except ValueError:\n",
    "                        post_time = datetime.strptime(time_value, '%Y-%m-%d %H:%M')  # 不含秒\n",
    "\n",
    "                    # 如果帖子不在24小时内，跳过后续处理\n",
    "                    if now - post_time > timedelta(days=1):\n",
    "                        continue  # 跳过后续处理\n",
    "\n",
    "                    # 如果在24小时内，继续处理\n",
    "                    headlines.append(title_element['title'])\n",
    "                    web_urls.append(link)\n",
    "                    authors.append(author_element.text.strip())\n",
    "                    dates.append(time_value)\n",
    "\n",
    "                    # 提取正文文本\n",
    "                    text_content = \"\"\n",
    "                    image_content = post_soup.find_all('img')\n",
    "                    script = post_soup.find('script', type='application/ld+json')\n",
    "                    if script:\n",
    "                        json_str = script.string.replace('\\n', '').replace('\\r', '').strip()\n",
    "                        try:\n",
    "                            json_data = json.loads(json_str)\n",
    "                            text_content = json_data.get('text', '')\n",
    "                        except json.JSONDecodeError:\n",
    "                            text_content = \"JSON解析错误\"\n",
    "                    else:\n",
    "                        text_content = \"NA\"\n",
    "\n",
    "                    if text_content != \"NA\" and text_content != \"\":\n",
    "                        post_content.append(text_content)\n",
    "                    elif image_content and text_content == \"\":\n",
    "                        post_content.append(\"image content\")  \n",
    "                    else:\n",
    "                        post_content.append(\"No valid content\")\n",
    "\n",
    "                    # 提取评论\n",
    "                    comments = []\n",
    "                    for comment_item in post_soup.find_all('li', class_='comment-item'):\n",
    "                        if '不可见' in comment_item.text:\n",
    "                            continue  # 跳过不可见的评论\n",
    "                        reply_content = comment_item.find('div', class_='reply-content')\n",
    "                        if reply_content:\n",
    "                            comment_text = reply_content.get_text(strip=True)\n",
    "                            comments.append(comment_text)\n",
    "                    comments_list.append(\" | \".join(comments) if comments else \"NA\")\n",
    "\n",
    "# 检查数据长度是否一致\n",
    "if not (len(headlines) == len(authors) == len(dates) == len(web_urls) == len(post_content) == len(comments_list)):\n",
    "    print(\"数据长度不一致，请检查抓取逻辑\")\n",
    "    print(f\"提取的标题数量: {len(headlines)}, 作者数量: {len(authors)}, 日期数量: {len(dates)}, URL数量: {len(web_urls)}, 内容数量: {len(post_content)}, 评论数量: {len(comments_list)}\")\n",
    "\n",
    "# 将数据存储到DataFrame\n",
    "douban_data = pd.DataFrame({\n",
    "    'title': headlines,\n",
    "    'username': authors,\n",
    "    'post_time': dates,\n",
    "    'post_content': post_content,\n",
    "    'replies': comments_list,\n",
    "    'url': web_urls\n",
    "})\n",
    "\n",
    "douban_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导出为csv\n",
    "douban_data.to_csv('Douban_data460410_3.csv',encoding='utf-8-sig',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导出为excel\n",
    "import openpyxl\n",
    "douban_data.to_excel('Douban_data729922.xlsx', index=False, engine='openpyxl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
